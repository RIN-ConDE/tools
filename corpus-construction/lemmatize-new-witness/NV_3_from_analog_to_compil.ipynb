{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Analog output file into XML attribute values\n",
    "\n",
    "* __Note__: Due to the fact that on GitHub the `@` sign is used to tag users, it is replaced by `att.` in XPath expressions.\n",
    "* __Note__: Analog uses UTF-16 encoding, but this script needs UTF-8 encoding: the CSV input file needs to be converted to UTF-8 before being given to the present script.\n",
    "\n",
    "This script takes a CSV table made by Analog as an output for its automatic analysis. This table has one line per token and one column per possible part-of-speach category. When several lemmas and/or POS are possible for a single form, Analog does not look at the context of a token to decide which it actually is. Instead it simply writes, in each possible POS column, the corresponding lemma. One column also contains \"VA/DS\" if Analog was sure of its one result. The much simplified result could therefore be as follows for the tokens \"au contraire\":\n",
    "\n",
    "| Mot n° | Forme rencontrée | Mode validation | Ag | Nc | S+Da | Vvn |\n",
    "|------------|---------|---------|---------|----------|------|------|\n",
    "| 31772 | au | VA/DS | | | À+LE | |\n",
    "| 31773 | contraire | | CONTRAIRE | CONTRAIRE | | CONTRAIRE |\n",
    "\n",
    "With this table, for each current line (=token), the present script looks for columns with text inside, and takes the names of these columns and their contents. To include them in a TEI-XML file as values of `att.pos` and `att.lemma`, the pertinent column names are joined with a pipe between them, as are their contents. The order is kept as a way to put together POS and lemma if needed later on. If, like in the previous example, all POS have an identical lemma, only one copy is taken.\n",
    "\n",
    "The script produces another CSV table, still with one token per line, but with columns reorganised:\n",
    "\n",
    "| Numero de token | Mot forme | Validation automatique | Lemme(s) | POS |\n",
    "|-----------------|-----------|------------------------|----------|-----|\n",
    "| 31772 | au | oui | À+LE | S+Da |\n",
    "| 31773 | contraire | non | CONTRAIRE | Ag¦Nc¦Vvn |\n",
    "\n",
    "### FUNCTION: compile information and write a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compil_analog(chemin_entree, chemin_sortie):\n",
    "    \n",
    "    \"\"\"\n",
    "    Fonction récupérant un fichier CSV produit par Analog\n",
    "    pour produire un nouveau CSV donnant aux informations\n",
    "    la forme dans laquelle elles doivent être transcrites\n",
    "    en XML-TEI.\n",
    "    \n",
    "    Attention : \n",
    "    \n",
    "        - Analog produit un fichier en UTF-16, il faut donc\n",
    "    le convertir en UTF-8 avant de pouvoir l'utiliser ici.\n",
    "        - L'ordre et le nombre de colonnes est conditionné par\n",
    "    les réglages faits sur Analog avant l'analyse des tokens.\n",
    "    Les variables de la fonction sont donc conçues pour\n",
    "    fonctionner avec un réglage particulier choisi pour\n",
    "    le corpus du projet CONDÉ par le Dr Mathieu Goux.\n",
    "        - À cause de problèmes avec les virgules, nous avions\n",
    "    changé les séparateurs de colonne en points-virgules. Le\n",
    "    CSV produit par ce script rétablit la virgule comme\n",
    "    séparateur.\n",
    "    \n",
    "    :param chemin_entree: Le chemin interne du fichier CSV\n",
    "    contenant l'analyse d'Analog à convertir.\n",
    "    \n",
    "    :param chemin_sortie: Le chemin interne du fichier CSV\n",
    "    à créer, dans lequel seront stockées les informations\n",
    "    une fois converties.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    import csv\n",
    "    import re\n",
    "    \n",
    "    # Le séparateur choisi pour séparer deux analyses concurrentes pour un même token.\n",
    "    separateur = \"|\"\n",
    "    \n",
    "    # Le réglage choisi pour Analog ne produisant qu'un niveau de lemme, les deux formes\n",
    "    # données sont identiques : on ne garde donc que la première. Cette RegEx permet de\n",
    "    # sélectionner un couple de parenthèses et leur contenu.\n",
    "    parentheses = re.compile(r\"\\([^\\)]+\\)\")\n",
    "    \n",
    "    # Les colonnes du futur fichier CSV de sortie.\n",
    "    colonnes = [\"Numero de token\", \"Mot forme\", \"Validation automatique\", \"Lemme(s)\", \"POS\"]\n",
    "    \n",
    "    # De quoi compter les tokens validés automatiquement par Analog :\n",
    "    compteur_total = 0\n",
    "    compteur_valides = 0\n",
    "    \n",
    "    \n",
    "    # Lecture du fichier CSV d'Analog.\n",
    "    with open(chemin_entree) as csv_a_lire:\n",
    "        csv_lu = csv.DictReader(csv_a_lire, delimiter=\";\")\n",
    "        \n",
    "        # Ouverture du fichier CSV de sortie.\n",
    "        with open(chemin_sortie, 'w') as csv_a_ecrire:\n",
    "            a_ecrire = csv.DictWriter(csv_a_ecrire, fieldnames=colonnes)\n",
    "            \n",
    "            # Écriture des noms des colonnes en première ligne.\n",
    "            a_ecrire.writeheader()\n",
    "        \n",
    "            # On boucle sur les lignes du CSV d'Analog.\n",
    "            for mot in csv_lu:\n",
    "                compteur_total += 1\n",
    "                \n",
    "                # On stocke l'identifiant du mot dans \"num\"\n",
    "                # et on ajoute 1 car Analog indexe à partir de 0.\n",
    "                num = int(mot[\"Mot n°\"]) + 1\n",
    "                \n",
    "                # On stocke le mot-forme dans \"forme\".\n",
    "                forme = mot[\"Forme rencontrée\"]\n",
    "                \n",
    "                # Si Analog n'a pas vu d'ambiguïté, on renseigne\n",
    "                # automatiquement les valeurs restantes.\n",
    "                if mot[\"Mode Validation\"] == \"VA/DS\":\n",
    "                    compteur_valides += 1\n",
    "                    validation = \"yes\"\n",
    "                    lemma = mot[\"sous-type 1.1\"]\n",
    "                    pos = mot[\"Niveau 1\"]\n",
    "                    \n",
    "                # Si Analog n'était pas sûr, on compile les différentes\n",
    "                # valeurs possibles avant de les renseigner.\n",
    "                else:\n",
    "                    validation = \"no\"\n",
    "                    lemma_list = []\n",
    "                    pos_list = []\n",
    "                    \n",
    "                    # On boucle sur les noms de colonnes.\n",
    "                    for colonne in mot.keys():\n",
    "                        \n",
    "                        # En excluant les deux ne correspondant pas à\n",
    "                        # l'analyse d'Analog.\n",
    "                        if colonne != \"Mot n°\" and colonne != \"Forme rencontrée\":\n",
    "                            \n",
    "                            # Si la colonne n'est pas vide dans la ligne courante.\n",
    "                            if mot[colonne]:\n",
    "                                \n",
    "                                # On ajoute son contenu, avant les parenthèses,\n",
    "                                # à la liste de lemmes possibles.\n",
    "                                lemma_list.append(parentheses.sub(\"\",mot[colonne]))\n",
    "                                \n",
    "                                # On ajoute son nom à la liste de POS possibles.\n",
    "                                pos_list.append(colonne)\n",
    "                    \n",
    "                    # On joint les deux listes en séparant les possibilités\n",
    "                    # par le pipe, défini en début de fonction.\n",
    "                    if len(set(lemma_list)) == 1:\n",
    "                        lemma = lemma_list[0]\n",
    "                    else:\n",
    "                        lemma = separateur.join(lemma_list)\n",
    "                    \"\"\"if re.fullmatch(lemmes_identiques, lemma):\n",
    "                        lemma = lemma_list[0]\"\"\"\n",
    "                        \n",
    "                    pos = separateur.join(pos_list)\n",
    "                \n",
    "                # On crée une nouvelle ligne dans le fichier de sortie et\n",
    "                # on y renseigne les informations compilées pour le mot courant.\n",
    "                \n",
    "                a_ecrire.writerow({\n",
    "                    'Numero de token': num,\n",
    "                    'Mot forme': forme,\n",
    "                    'Validation automatique': validation,\n",
    "                    'Lemme(s)': lemma,\n",
    "                    'POS': pos\n",
    "                })\n",
    "    print(compteur_valides, \"validés : \", round(compteur_valides * 100 / compteur_total, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370 validés :  27.2 %\n"
     ]
    }
   ],
   "source": [
    "# Utilisation de la fonction. Changer les chemins quand nécessaire.\n",
    "\n",
    "compil_analog('/home/erminea/Documents/CONDE/Morisse-TS-XML/Morisse_Analog.csv',\n",
    "             '/home/erminea/Documents/CONDE/Morisse-TS-XML/morisse_analog_compile.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
