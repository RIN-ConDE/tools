{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(csv_entree, csv_sortie_ambig, csv_sortie_inc, stats_txt):\n",
    "    \n",
    "    \"\"\"\n",
    "        Fonction permettant, depuis un CSV extrait avec les colonnes\n",
    "            - ID (numéro de token)\n",
    "            - TOKEN (mot_forme)\n",
    "            - LEMME (lemme ou liste des lemmes, séparés par des '|'\n",
    "            - POS (pos ou liste des pos, séparés par des '|',\n",
    "        \n",
    "        1 - d'extraire les tokens où subsiste une ambiguïté sur le POS\n",
    "        dans un nouveau CSV avec le contexte (3 tokens à gauche,\n",
    "        3 tokens à droite, ainsi que leurs POS respectifs)\n",
    "        \n",
    "        2 - de calculer :\n",
    "        - le total de tokens dans le fichier,\n",
    "        - le pourcentage de lemmes résolus,\n",
    "        - le pourcentage de pos résolus,\n",
    "        - le nombre de lemmes inconnus,\n",
    "        - le pourcentage de tokens extraits car toujours ambigus.\n",
    "        \n",
    "        :param csv_entree: Le chemin interne du fichier CSV dont on\n",
    "            souhaite extraire les tokens et calculer les pourcentages.\n",
    "        :param csv_sortie: Le chemin interne du fichier CSV où seront\n",
    "            extraits les tokens encore ambigus.\n",
    "    \"\"\"\n",
    "        \n",
    "    import csv\n",
    "    \n",
    "    # Dictionnaires servant à l'écriture du nouveau CSV avec tokens ambigus.\n",
    "    dico_mots = {}\n",
    "    dico_local = {}\n",
    "    dico_ambig = {}\n",
    "    dico_inc = {}\n",
    "    \n",
    "    # Compteur pour les identifiants de dico_mots.\n",
    "    identifiant = 1\n",
    "    \n",
    "    # Séparateur de valeurs pour les colonnes contenant le POS.\n",
    "    intervale = \" - \"\n",
    "    \n",
    "    # Colonnes du futur fichier CSV avec tokens ambigus.\n",
    "    colonnes = ['POS g', 'G1', 'G2', 'G3', 'TOKEN', 'D1', 'D2', 'D3', 'POS d']\n",
    "    \n",
    "    # Compteurs servant à l'établissement des pourcentages.\n",
    "    nb_total_tokens = 0\n",
    "    pos_ambigus = 0\n",
    "    lemmes_uniques = 0\n",
    "    pos_uniques = 0\n",
    "    lemmes_inc = 0\n",
    "    \n",
    "    \n",
    "    # Lecture du fichier CSV d'entrée et stockage de l'information dans csv_lu.\n",
    "    with open(csv_entree) as csv_a_lire:\n",
    "        csv_lu = csv.DictReader(csv_a_lire, delimiter=\";\") #\n",
    "        \n",
    "        for row in csv_lu:\n",
    "            \n",
    "            # Établissement du dictionnaire servant à la création du nouveau CSV.\n",
    "            dico_mots[int(row['ID'])] = row\n",
    "            \n",
    "            # Calcul du nombre de lemmes et pos résolus, ainsi que du total de tokens.\n",
    "            if \"|\" not in row['LEMMES']:\n",
    "                lemmes_uniques += 1\n",
    "            if \"|\" not in row['POS']:\n",
    "                pos_uniques += 1\n",
    "            if row['LEMMES'] == 'INC':\n",
    "                lemmes_inc += 1\n",
    "            nb_total_tokens += 1\n",
    "    \n",
    "    \n",
    "    # On boucle sur le dictionnaire des tokens pour créer le concordancier.\n",
    "    for identifiant in dico_mots.keys():\n",
    "        \n",
    "        # Création des identifiants des contextes les plus éloignés.\n",
    "        g1 = identifiant - 3\n",
    "        d3 = identifiant + 3\n",
    "        \n",
    "        # Conditions : on ne créera ces entrées de dictionnaire que si le POS est ambigu,\n",
    "        # et s'il y a bien trois tokens de contexte à inclure de chaque côté\n",
    "        # (ce qui sera le cas à partir du token n°4 et jusqu'au token n°-4).\n",
    "        \n",
    "        if g1 in dico_mots.keys() and d3 in dico_mots.keys() and \"|\" in dico_mots[identifiant]['POS']:\n",
    "            \n",
    "            # Si les conditions sont réunies, on peut ajouter 1 au compteur de POS ambigus.\n",
    "            pos_ambigus += 1\n",
    "            \n",
    "            # On crée les identifiants des autres tokens de contexte.\n",
    "            g2 = identifiant - 2\n",
    "            g3 = identifiant - 1\n",
    "            d1 = identifiant + 1\n",
    "            d2 = identifiant + 2\n",
    "            \n",
    "            # On crée une liste des POS pour le contexte gauche et droit, séparément.\n",
    "            posg = [dico_mots[g1]['POS'], dico_mots[g2]['POS'], dico_mots[g3]['POS']]\n",
    "            posd = [dico_mots[d1]['POS'], dico_mots[d2]['POS'], dico_mots[d3]['POS']]\n",
    "            \n",
    "            # On ajoute au dictionnaire local les valeurs construites\n",
    "            # d'après le token et son contexte.\n",
    "            \n",
    "            dico_local['posG'] = intervale.join(posg)\n",
    "            dico_local['G1'] = dico_mots[g1]['TOKEN']\n",
    "            dico_local['G2'] = dico_mots[g2]['TOKEN']\n",
    "            dico_local['G3'] = dico_mots[g3]['TOKEN']\n",
    "            dico_local['token'] = dico_mots[identifiant]['TOKEN'] + \" - \" + str(identifiant)\n",
    "            dico_local['D1'] = dico_mots[d1]['TOKEN']\n",
    "            dico_local['D2'] = dico_mots[d2]['TOKEN']\n",
    "            dico_local['D3'] = dico_mots[d3]['TOKEN']\n",
    "            dico_local['posD'] = intervale.join(posd)\n",
    "            \n",
    "            # On ajoute le dictionnaire pour le token en cours\n",
    "            # dans le dictionnaire final, comme valeur,\n",
    "            # avec pour identifiant celui du token central.\n",
    "            \n",
    "            dico_ambig[identifiant] = dico_local\n",
    "            identifiant += 1\n",
    "            dico_local = {}\n",
    "            \n",
    "        elif g1 in dico_mots.keys() and d3 in dico_mots.keys() and dico_mots[identifiant]['POS'] == \"Inconnu\":\n",
    "            \n",
    "            # On crée les identifiants des autres tokens de contexte.\n",
    "            g2 = identifiant - 2\n",
    "            g3 = identifiant - 1\n",
    "            d1 = identifiant + 1\n",
    "            d2 = identifiant + 2\n",
    "            \n",
    "            # On crée une liste des POS pour le contexte gauche et droit, séparément.\n",
    "            posg = [dico_mots[g1]['POS'], dico_mots[g2]['POS'], dico_mots[g3]['POS']]\n",
    "            posd = [dico_mots[d1]['POS'], dico_mots[d2]['POS'], dico_mots[d3]['POS']]\n",
    "            \n",
    "            # On ajoute au dictionnaire local les valeurs construites\n",
    "            # d'après le token et son contexte.\n",
    "            \n",
    "            dico_local['posG'] = intervale.join(posg)\n",
    "            dico_local['G1'] = dico_mots[g1]['TOKEN']\n",
    "            dico_local['G2'] = dico_mots[g2]['TOKEN']\n",
    "            dico_local['G3'] = dico_mots[g3]['TOKEN']\n",
    "            dico_local['token'] = dico_mots[identifiant]['TOKEN'] + \" - \" + str(identifiant)\n",
    "            dico_local['D1'] = dico_mots[d1]['TOKEN']\n",
    "            dico_local['D2'] = dico_mots[d2]['TOKEN']\n",
    "            dico_local['D3'] = dico_mots[d3]['TOKEN']\n",
    "            dico_local['posD'] = intervale.join(posd)\n",
    "            \n",
    "            # On ajoute le dictionnaire pour le token en cours\n",
    "            # dans le dictionnaire final, comme valeur,\n",
    "            # avec pour identifiant celui du token central.\n",
    "            \n",
    "            dico_inc[identifiant] = dico_local\n",
    "            identifiant += 1\n",
    "            dico_local = {}\n",
    "        \n",
    "    # On ouvre le CSV de sortie en mode écriture et on écrit les noms des colonnes.\n",
    "    \n",
    "    with open(csv_sortie_ambig, 'w') as csv_a_ecrire:\n",
    "        a_ecrire = csv.DictWriter(csv_a_ecrire, fieldnames = colonnes)\n",
    "        # Écrire les noms des colonnes.\n",
    "        a_ecrire.writeheader()\n",
    "        \n",
    "        # On boucle sur les clés du dictionnaire final.\n",
    "        for identifiant in dico_ambig.keys():\n",
    "            \n",
    "            a_ecrire.writerow({\n",
    "                'POS g' : dico_ambig[identifiant]['posG'],\n",
    "                'G1' : dico_ambig[identifiant]['G1'],\n",
    "                'G2' : dico_ambig[identifiant]['G2'],\n",
    "                'G3' : dico_ambig[identifiant]['G3'],\n",
    "                'TOKEN' : dico_ambig[identifiant]['token'],\n",
    "                'D1' : dico_ambig[identifiant]['D1'],\n",
    "                'D2' : dico_ambig[identifiant]['D2'],\n",
    "                'D3' : dico_ambig[identifiant]['D3'],\n",
    "                'POS d' : dico_ambig[identifiant]['posD']\n",
    "            })\n",
    "    \n",
    "    with open(csv_sortie_inc, 'w') as csv_a_ecrire:\n",
    "        a_ecrire = csv.DictWriter(csv_a_ecrire, fieldnames = colonnes)\n",
    "        # Écrire les noms des colonnes.\n",
    "        a_ecrire.writeheader()\n",
    "        \n",
    "        # On boucle sur les clés du dictionnaire final.\n",
    "        for identifiant in dico_inc.keys():\n",
    "            \n",
    "            a_ecrire.writerow({\n",
    "                'POS g' : dico_inc[identifiant]['posG'],\n",
    "                'G1' : dico_inc[identifiant]['G1'],\n",
    "                'G2' : dico_inc[identifiant]['G2'],\n",
    "                'G3' : dico_inc[identifiant]['G3'],\n",
    "                'TOKEN' : dico_inc[identifiant]['token'],\n",
    "                'D1' : dico_inc[identifiant]['D1'],\n",
    "                'D2' : dico_inc[identifiant]['D2'],\n",
    "                'D3' : dico_inc[identifiant]['D3'],\n",
    "                'POS d' : dico_inc[identifiant]['posD']\n",
    "            })\n",
    "    \n",
    "    # L'écriture du CSV étant terminée, on calcule les pourcentages.\n",
    "    \n",
    "    pourcentage_lemmes = lemmes_uniques * 100 / nb_total_tokens\n",
    "    pourcentage_pos = pos_uniques * 100 / nb_total_tokens\n",
    "    pourcentage_lemmes_inc = lemmes_inc * 100 / nb_total_tokens\n",
    "    pourcentage_extraits = pos_ambigus * 100 / (nb_total_tokens-4)\n",
    "    \n",
    "    # On donne le résultat des calculs de pourcentages.\n",
    "    \n",
    "    with open(stats_txt, 'w') as txttobe:\n",
    "        \n",
    "        txttobe.write(\"À partir du fichier '\" + csv_entree.split(\"/\")[-1] + \"' :\\n\\n\")\n",
    "        txttobe.write(str(round(pourcentage_lemmes,2)) + \"% de lemmes uniques.\\n\")\n",
    "        txttobe.write(str(round(pourcentage_pos,2)) + \"% de POS uniques.\\n\")\n",
    "        txttobe.write(str(lemmes_inc) + \" lemmes inconnus, soit \" + str(round(pourcentage_lemmes_inc,2)) + \"%.\\n\")\n",
    "        txttobe.write(str(pos_ambigus) + \"(\" + str(round(pourcentage_extraits,2)) + \"%) POS ambigus extraits dans '\" + csv_sortie_ambig.split(\"/\")[-1] + \"'.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction('/home/erminea/Documents/CONDE/Encodage/basnage_tokens.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/basnage_tokens_ambig.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/basnage_tokens_inc.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/basnage_stats.txt')\n",
    "\n",
    "extraction('/home/erminea/Documents/CONDE/Encodage/berault_tokens.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/berault_tokens_ambig.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/berault_tokens_inc.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/berault_stats.txt')\n",
    "\n",
    "extraction('/home/erminea/Documents/CONDE/Encodage/instructions_tokens.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/instructions_tokens_ambig.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/instructions_tokens_inc.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/instructions_stats.txt')\n",
    "\n",
    "extraction('/home/erminea/Documents/CONDE/Encodage/merville_tokens.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/merville_tokens_ambig.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/merville_tokens_inc.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/merville_stats.txt')\n",
    "\n",
    "extraction('/home/erminea/Documents/CONDE/Encodage/pesnelle_tokens.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/pesnelle_tokens_ambig.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/pesnelle_tokens_inc.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/pesnelle_stats.txt')\n",
    "\n",
    "extraction('/home/erminea/Documents/CONDE/Encodage/rouille_tokens.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/rouille_tokens_ambig.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/rouille_tokens_inc.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/rouille_stats.txt')\n",
    "\n",
    "extraction('/home/erminea/Documents/CONDE/Encodage/ruines_tokens.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/ruines_tokens_ambig.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/ruines_tokens_inc.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/ruines_stats.txt')\n",
    "\n",
    "extraction('/home/erminea/Documents/CONDE/Encodage/tac_tokens.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/tac_tokens_ambig.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/tac_tokens_inc.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/tac_stats.txt')\n",
    "\n",
    "extraction('/home/erminea/Documents/CONDE/Encodage/terrien_tokens.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/terrien_tokens_ambig.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/terrien_tokens_inc.csv',\n",
    "          '/home/erminea/Documents/CONDE/Encodage/terrien_stats.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
